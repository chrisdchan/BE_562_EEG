{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from naive_bayes import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = mat73.loadmat('preprocessed_data/all_subjects/test.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mat73.loadmat('preprocessed_data/all_subjects/train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_one_sample = mat73.loadmat('preprocessed_data/one_subject/test.mat')\n",
    "train_data_one_sample = mat73.loadmat('preprocessed_data/one_subject/train.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which class are we predicting\n",
    "CLASS = 'visible'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.load(('distributions/' + CLASS + '/cov.npy'))\n",
    "mu_bar = np.load(('distributions/' + CLASS + '/mu_bar.npy'))\n",
    "single_normal = np.load(('distributions/' + CLASS + '/single_normal.npy'))\n",
    "parents = np.load(('distributions/' + CLASS + '/parents.npy'))\n",
    "parents = parents.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "import math\n",
    "\n",
    "class Model():\n",
    "\n",
    "    def __init__(self, \n",
    "                 single_normal, \n",
    "                 mu_bar, \n",
    "                 cov, \n",
    "                 parents, \n",
    "                 priors,\n",
    "                 num_classes=2, \n",
    "                 num_dims=300):\n",
    "\n",
    "        self.single_normal = single_normal\n",
    "        self.mu_bar = mu_bar\n",
    "        self.cov = cov\n",
    "        self.parents = parents\n",
    "        self.priors = priors\n",
    "        self.num_classes = num_classes\n",
    "        self.num_dims = num_dims\n",
    "        self.mu_parents = single_normal[parents, :, 0]\n",
    "        self.sig_parents = single_normal[parents, :, 1]\n",
    "\n",
    "    def _normal_pdf(self, x, mu, sigma):\n",
    "        coef = 1 / (sigma * math.sqrt(2 * math.pi))\n",
    "        return coef * math.exp(-0.5 * math.pow((x - mu) / sigma, 2))\n",
    "\n",
    "    def classify(self, x):\n",
    "        likelihood = np.ones((self.num_classes,))\n",
    "        for c in range(self.num_classes):\n",
    "\n",
    "            node_probabilities = np.ones((self.num_dims, ))\n",
    "\n",
    "            mu_0 = self.single_normal[0][c][0]\n",
    "            sigma_0 = self.single_normal[0][c][1]\n",
    "\n",
    "            node_probabilities[0] = self._normal_pdf(x[0], mu_0, sigma_0) \n",
    "\n",
    "            for node in range(1, self.num_dims):\n",
    "                mu_bar = self.mu_bar[node, c]\n",
    "                cov = self.cov[node, c]\n",
    "\n",
    "                mu_parent = self.mu_parents[node, c] \n",
    "                sigma_parent = self.sig_parents[node, c] \n",
    "\n",
    "                node_value = x[node]\n",
    "                parent_value = x[self.parents[node]]\n",
    "                joint_value = np.array([node_value, parent_value])\n",
    "\n",
    "                joint_prob = multivariate_normal.pdf(joint_value, mu_bar, cov)\n",
    "                parent_prob = self._normal_pdf(parent_value, mu_parent, sigma_parent)\n",
    "                node_probabilities[node] = joint_prob / parent_prob\n",
    "\n",
    "            log_node_probabilities = np.log(node_probabilities) \n",
    "            likelihood[c] = np.sum(log_node_probabilities) + math.log(self.priors[c])\n",
    "\n",
    "        pred = np.argmax(likelihood)\n",
    "        return pred, likelihood\n",
    "\n",
    "    def run_test(self, X, y):\n",
    "        N, _ = X.shape\n",
    "\n",
    "        correct = 0\n",
    "        correct_local = 0\n",
    "\n",
    "        predictions = []\n",
    "        for i in range(N):\n",
    "            x = X[i]\n",
    "            prediction, likelihood = self.classify(x)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "            if prediction == y[i]:\n",
    "                correct += 1\n",
    "                correct_local += 1\n",
    "\n",
    "            if i % 100 == 0 and i != 0:\n",
    "                print(f'Running Accuracy: {correct / i} windowed: {correct_local / 100} for {i} samples')\n",
    "                print(predictions)\n",
    "                predictions = []\n",
    "                correct_local = 0\n",
    "\n",
    "        accuracy = correct / N\n",
    "        print(f'Accuracy is {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "\n",
    "class NaiveBayes():\n",
    "\n",
    "    def __init__(self, single_normal, priors, num_classes=2, num_dims=300):\n",
    "        self.single_normal = single_normal\n",
    "        self.num_classes = num_classes\n",
    "        self.num_dims = num_dims\n",
    "        self.priors = priors\n",
    "\n",
    "    def classify(self, x):\n",
    "        likelihood = np.zeros((self.num_classes, ))\n",
    "\n",
    "        for c in range(self.num_classes):\n",
    "            mus = self.single_normal[:, c, 0]\n",
    "            sigmas = self.single_normal[:, c, 1]\n",
    "            node_probs = norm.pdf(x, mus, sigmas)\n",
    "            log_node_probs = np.log(node_probs)\n",
    "            likelihood[c] = np.sum(log_node_probs) + self.priors[c]\n",
    "\n",
    "        return np.argmax(likelihood)\n",
    "\n",
    "    # def classi(self, x):\n",
    "    #     node_probs = norm.pdf(\n",
    "    #         x, \n",
    "    #         self.single_normal[:, :, 0], \n",
    "    #         self.single_normal[:, :, 1]\n",
    "    #     )\n",
    "    #     x_given_class = np.prod(node_probs, axis=0)\n",
    "    #     return np.argmax(x_given_class)\n",
    "\n",
    "    def test(self, X, y):\n",
    "        N, _ = X.shape\n",
    "        correct = 0\n",
    "\n",
    "        num_predicted_0 = 0\n",
    "        num_predicted_1 = 0\n",
    "\n",
    "        for i in range(N):\n",
    "            x = X[i]\n",
    "            prediction = self.classify(x)\n",
    "\n",
    "            if prediction == 0:\n",
    "                num_predicted_0 += 1\n",
    "            elif prediction == 1:\n",
    "                num_predicted_1 += 1\n",
    "            else:\n",
    "                assert False\n",
    "\n",
    "            if prediction == y[i]:\n",
    "                correct += 1\n",
    "\n",
    "            if i % 500 == 0 and i != 0:\n",
    "                print(f'Running Accuracy is {correct / i} for {i} samples')\n",
    "                print(f'    num 1s: {num_predicted_1}, num 0s: {num_predicted_0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Accuracy: 0.42 windowed: 0.42 for 100 samples\n",
      "Running Accuracy: 0.405 windowed: 0.39 for 200 samples\n",
      "Running Accuracy: 0.4 windowed: 0.39 for 300 samples\n",
      "Running Accuracy: 0.4 windowed: 0.4 for 400 samples\n",
      "Running Accuracy: 0.402 windowed: 0.41 for 500 samples\n",
      "Running Accuracy: 0.41833333333333333 windowed: 0.5 for 600 samples\n",
      "Running Accuracy: 0.41285714285714287 windowed: 0.38 for 700 samples\n",
      "Running Accuracy: 0.41375 windowed: 0.42 for 800 samples\n",
      "Running Accuracy: 0.4166666666666667 windowed: 0.44 for 900 samples\n",
      "Running Accuracy: 0.416 windowed: 0.41 for 1000 samples\n",
      "Running Accuracy: 0.4218181818181818 windowed: 0.48 for 1100 samples\n",
      "Running Accuracy: 0.42083333333333334 windowed: 0.41 for 1200 samples\n",
      "Running Accuracy: 0.42230769230769233 windowed: 0.44 for 1300 samples\n",
      "Running Accuracy: 0.42 windowed: 0.39 for 1400 samples\n",
      "Running Accuracy: 0.4226666666666667 windowed: 0.46 for 1500 samples\n",
      "Running Accuracy: 0.4225 windowed: 0.42 for 1600 samples\n",
      "Running Accuracy: 0.4194117647058824 windowed: 0.37 for 1700 samples\n",
      "Running Accuracy: 0.41833333333333333 windowed: 0.4 for 1800 samples\n",
      "Running Accuracy: 0.4189473684210526 windowed: 0.43 for 1900 samples\n",
      "Running Accuracy: 0.417 windowed: 0.38 for 2000 samples\n",
      "Running Accuracy: 0.4166666666666667 windowed: 0.41 for 2100 samples\n",
      "Running Accuracy: 0.4172727272727273 windowed: 0.43 for 2200 samples\n",
      "Running Accuracy: 0.4152173913043478 windowed: 0.37 for 2300 samples\n",
      "Running Accuracy: 0.41333333333333333 windowed: 0.37 for 2400 samples\n",
      "Running Accuracy: 0.414 windowed: 0.43 for 2500 samples\n",
      "Running Accuracy: 0.41384615384615386 windowed: 0.41 for 2600 samples\n",
      "Running Accuracy: 0.4151851851851852 windowed: 0.45 for 2700 samples\n",
      "Running Accuracy: 0.41464285714285715 windowed: 0.4 for 2800 samples\n",
      "Running Accuracy: 0.41586206896551725 windowed: 0.45 for 2900 samples\n",
      "Running Accuracy: 0.41133333333333333 windowed: 0.28 for 3000 samples\n",
      "Running Accuracy: 0.41096774193548385 windowed: 0.4 for 3100 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m priors \u001b[38;5;241m=\u001b[39m [prior_0, prior_1]\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(single_normal, mu_bar, cov, parents, priors)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# nb = NaiveBayes(single_normal, priors)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# nb.test(test_X, test_y)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[46], line 71\u001b[0m, in \u001b[0;36mModel.run_test\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[0;32m     70\u001b[0m     x \u001b[38;5;241m=\u001b[39m X[i]\n\u001b[1;32m---> 71\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# predictions.append(prediction)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m==\u001b[39m y[i]:\n",
      "Cell \u001b[1;32mIn[46], line 52\u001b[0m, in \u001b[0;36mModel.classify\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m parent_value \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparents[node]]\n\u001b[0;32m     50\u001b[0m joint_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([node_value, parent_value])\n\u001b[1;32m---> 52\u001b[0m joint_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmultivariate_normal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoint_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m parent_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normal_pdf(parent_value, mu_parent, sigma_parent)\n\u001b[0;32m     54\u001b[0m node_probabilities[node] \u001b[38;5;241m=\u001b[39m joint_prob \u001b[38;5;241m/\u001b[39m parent_prob\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\stats\\_multivariate.py:580\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.pdf\u001b[1;34m(self, x, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cov\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_singular\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    562\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Multivariate normal probability density function.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m     dim, mean, cov_object \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m    582\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_quantiles(x, dim)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\stats\\_multivariate.py:417\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._process_parameters\u001b[1;34m(self, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    410\u001b[0m dim, mean, cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_parameters_psd(\u001b[38;5;28;01mNone\u001b[39;00m, mean, cov)\n\u001b[0;32m    411\u001b[0m \u001b[38;5;66;03m# After input validation, some methods then processed the arrays\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;66;03m# with a `_PSD` object and used that to perform computation.\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;66;03m# To avoid branching statements in each method depending on whether\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m# `cov` is an array or `Covariance` object, we always process the\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# array with `_PSD`, and then use wrapper that satisfies the\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# `Covariance` interface, `CovViaPSD`.\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m psd \u001b[38;5;241m=\u001b[39m \u001b[43m_PSD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_singular\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m cov_object \u001b[38;5;241m=\u001b[39m _covariance\u001b[38;5;241m.\u001b[39mCovViaPSD(psd)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dim, mean, cov_object\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\stats\\_multivariate.py:162\u001b[0m, in \u001b[0;36m_PSD.__init__\u001b[1;34m(self, M, cond, rcond, lower, check_finite, allow_singular)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_M \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(M)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Compute the symmetric eigendecomposition.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Note that eigh takes care of array conversion, chkfinite,\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# and assertion that the matrix is square.\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m s, u \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m eps \u001b[38;5;241m=\u001b[39m _eigvalsh_to_eps(s, cond, rcond)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(s) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39meps:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\linalg\\_decomp.py:561\u001b[0m, in \u001b[0;36meigh\u001b[1;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite, subset_by_index, subset_by_value, driver)\u001b[0m\n\u001b[0;32m    558\u001b[0m         lwork_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlwork\u001b[39m\u001b[38;5;124m'\u001b[39m: lw}\n\u001b[0;32m    560\u001b[0m     drv_args\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m: lower, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompute_v\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _job \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m})\n\u001b[1;32m--> 561\u001b[0m     w, v, \u001b[38;5;241m*\u001b[39mother_args, info \u001b[38;5;241m=\u001b[39m \u001b[43mdrv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdrv_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlwork_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Generalized problem\u001b[39;00m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;66;03m# 'gvd' doesn't have lwork query\u001b[39;00m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgvd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_data_dict = test_data['test']\n",
    "test_X = test_data_dict['data']\n",
    "test_X = np.array(test_X)\n",
    "test_y = test_data_dict[CLASS]\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_data_dict = train_data['train']\n",
    "train_y = train_data_dict[CLASS]\n",
    "\n",
    "# Calculate Priors\n",
    "prior_1 = np.sum(train_y) / len(train_y)\n",
    "prior_0 = 1 - prior_1\n",
    "priors_state = [prior_0, prior_1]\n",
    "\n",
    "\n",
    "model = Model(single_normal, mu_bar, cov, parents, priors_state)\n",
    "model.run_test(test_X, test_y)\n",
    "\n",
    "# nb = NaiveBayes(single_normal, priors)\n",
    "# nb.test(test_X, test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_state_intuit = np.load('data/node_probs_state_intuit/cov.npy')\n",
    "mu_bar_state_intuit = np.load('data/node_probs_state_intuit/mu_bar.npy')\n",
    "single_normal_state_intuit = np.load('data/node_probs_state_intuit/single_normal.npy')\n",
    "parents_intuit = np.arange(-1, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dict = test_data['test']\n",
    "test_X = test_data_dict['data']\n",
    "test_X = np.array(test_X)\n",
    "test_y_vis = test_data_dict['visible']\n",
    "test_y_vis = np.array(test_y_vis)\n",
    "\n",
    "train_data_dict = train_data['train']\n",
    "train_y_vis = train_data_dict['visible']\n",
    "prior_1 = np.sum(train_y_vis) / len(train_y_vis)\n",
    "prior_0 = 1 - prior_1\n",
    "priors_state = [prior_0, prior_1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Accuracy: 0.42 windowed: 0.42 for 100 samples\n",
      "Running Accuracy: 0.41 windowed: 0.4 for 200 samples\n",
      "Running Accuracy: 0.4033333333333333 windowed: 0.39 for 300 samples\n",
      "Running Accuracy: 0.4 windowed: 0.39 for 400 samples\n",
      "Running Accuracy: 0.402 windowed: 0.41 for 500 samples\n",
      "Running Accuracy: 0.41833333333333333 windowed: 0.5 for 600 samples\n",
      "Running Accuracy: 0.41285714285714287 windowed: 0.38 for 700 samples\n",
      "Running Accuracy: 0.41375 windowed: 0.42 for 800 samples\n",
      "Running Accuracy: 0.4177777777777778 windowed: 0.45 for 900 samples\n",
      "Running Accuracy: 0.417 windowed: 0.41 for 1000 samples\n",
      "Running Accuracy: 0.4218181818181818 windowed: 0.47 for 1100 samples\n",
      "Running Accuracy: 0.42083333333333334 windowed: 0.41 for 1200 samples\n",
      "Running Accuracy: 0.42230769230769233 windowed: 0.44 for 1300 samples\n",
      "Running Accuracy: 0.42 windowed: 0.39 for 1400 samples\n",
      "Running Accuracy: 0.42333333333333334 windowed: 0.47 for 1500 samples\n",
      "Running Accuracy: 0.423125 windowed: 0.42 for 1600 samples\n",
      "Running Accuracy: 0.42 windowed: 0.37 for 1700 samples\n",
      "Running Accuracy: 0.41888888888888887 windowed: 0.4 for 1800 samples\n",
      "Running Accuracy: 0.41947368421052633 windowed: 0.43 for 1900 samples\n",
      "Running Accuracy: 0.4175 windowed: 0.38 for 2000 samples\n",
      "Running Accuracy: 0.41714285714285715 windowed: 0.41 for 2100 samples\n",
      "Running Accuracy: 0.4172727272727273 windowed: 0.42 for 2200 samples\n",
      "Running Accuracy: 0.4152173913043478 windowed: 0.37 for 2300 samples\n",
      "Running Accuracy: 0.41333333333333333 windowed: 0.37 for 2400 samples\n",
      "Running Accuracy: 0.4148 windowed: 0.45 for 2500 samples\n",
      "Running Accuracy: 0.4146153846153846 windowed: 0.41 for 2600 samples\n",
      "Running Accuracy: 0.4159259259259259 windowed: 0.45 for 2700 samples\n",
      "Running Accuracy: 0.4157142857142857 windowed: 0.41 for 2800 samples\n",
      "Running Accuracy: 0.41724137931034483 windowed: 0.46 for 2900 samples\n",
      "Running Accuracy: 0.4126666666666667 windowed: 0.28 for 3000 samples\n",
      "Running Accuracy: 0.412258064516129 windowed: 0.4 for 3100 samples\n",
      "Running Accuracy: 0.41125 windowed: 0.38 for 3200 samples\n",
      "Running Accuracy: 0.40969696969696967 windowed: 0.36 for 3300 samples\n",
      "Running Accuracy: 0.4097058823529412 windowed: 0.41 for 3400 samples\n",
      "Running Accuracy: 0.41 windowed: 0.42 for 3500 samples\n",
      "Running Accuracy: 0.4077777777777778 windowed: 0.33 for 3600 samples\n",
      "Running Accuracy: 0.4064864864864865 windowed: 0.36 for 3700 samples\n",
      "Running Accuracy: 0.40710526315789475 windowed: 0.43 for 3800 samples\n",
      "Running Accuracy: 0.40692307692307694 windowed: 0.4 for 3900 samples\n",
      "Running Accuracy: 0.4065 windowed: 0.39 for 4000 samples\n",
      "Running Accuracy: 0.4060975609756098 windowed: 0.39 for 4100 samples\n",
      "Running Accuracy: 0.405 windowed: 0.36 for 4200 samples\n",
      "Running Accuracy: 0.40581395348837207 windowed: 0.44 for 4300 samples\n",
      "Running Accuracy: 0.4043181818181818 windowed: 0.34 for 4400 samples\n",
      "Running Accuracy: 0.40355555555555556 windowed: 0.37 for 4500 samples\n",
      "Running Accuracy: 0.4032608695652174 windowed: 0.39 for 4600 samples\n",
      "Running Accuracy: 0.40425531914893614 windowed: 0.45 for 4700 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_20744\\3312700217.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  log_node_probabilities = np.log(node_probabilities)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Accuracy: 0.40479166666666666 windowed: 0.43 for 4800 samples\n",
      "Running Accuracy: 0.40551020408163263 windowed: 0.44 for 4900 samples\n",
      "Running Accuracy: 0.4088 windowed: 0.57 for 5000 samples\n",
      "Running Accuracy: 0.41 windowed: 0.47 for 5100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_20744\\3312700217.py:54: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  node_probabilities[node] = joint_prob / parent_prob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Accuracy: 0.4125 windowed: 0.54 for 5200 samples\n",
      "Running Accuracy: 0.4130188679245283 windowed: 0.44 for 5300 samples\n",
      "Running Accuracy: 0.4137037037037037 windowed: 0.45 for 5400 samples\n",
      "Running Accuracy: 0.4172727272727273 windowed: 0.61 for 5500 samples\n",
      "Running Accuracy: 0.41875 windowed: 0.5 for 5600 samples\n",
      "Running Accuracy: 0.4203508771929825 windowed: 0.51 for 5700 samples\n",
      "Running Accuracy: 0.42120689655172416 windowed: 0.47 for 5800 samples\n",
      "Running Accuracy: 0.4216949152542373 windowed: 0.45 for 5900 samples\n",
      "Running Accuracy: 0.4221666666666667 windowed: 0.45 for 6000 samples\n",
      "Running Accuracy: 0.4242622950819672 windowed: 0.55 for 6100 samples\n",
      "Running Accuracy: 0.42612903225806453 windowed: 0.54 for 6200 samples\n",
      "Running Accuracy: 0.4265079365079365 windowed: 0.45 for 6300 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(single_normal_state_intuit, mu_bar_state_intuit, cov_state_intuit, parents_intuit, priors_state)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[46], line 71\u001b[0m, in \u001b[0;36mModel.run_test\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[0;32m     70\u001b[0m     x \u001b[38;5;241m=\u001b[39m X[i]\n\u001b[1;32m---> 71\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# predictions.append(prediction)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m==\u001b[39m y[i]:\n",
      "Cell \u001b[1;32mIn[46], line 52\u001b[0m, in \u001b[0;36mModel.classify\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m parent_value \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparents[node]]\n\u001b[0;32m     50\u001b[0m joint_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([node_value, parent_value])\n\u001b[1;32m---> 52\u001b[0m joint_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmultivariate_normal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoint_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m parent_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normal_pdf(parent_value, mu_parent, sigma_parent)\n\u001b[0;32m     54\u001b[0m node_probabilities[node] \u001b[38;5;241m=\u001b[39m joint_prob \u001b[38;5;241m/\u001b[39m parent_prob\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\stats\\_multivariate.py:583\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.pdf\u001b[1;34m(self, x, mean, cov, allow_singular)\u001b[0m\n\u001b[0;32m    581\u001b[0m dim, mean, cov_object \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m    582\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_quantiles(x, dim)\n\u001b[1;32m--> 583\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_object\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((cov_object\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m<\u001b[39m dim)):\n\u001b[0;32m    585\u001b[0m     out_of_bounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcov_object\u001b[38;5;241m.\u001b[39m_support_mask(x\u001b[38;5;241m-\u001b[39mmean)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(single_normal_state_intuit, mu_bar_state_intuit, cov_state_intuit, parents_intuit, priors_state)\n",
    "model.run_test(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data/node_probs_state_intuit_one_patient/'\n",
    "cov_state_intuit_one = np.load(root + 'cov.npy')\n",
    "mu_bar_state_intuit_one = np.load(root + 'mu_bar.npy')\n",
    "single_normal_state_intuit_one = np.load(root + 'single_normal.npy')\n",
    "parents_intuit = np.arange(-1, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37524240465416936, 0.6247575953458306]\n"
     ]
    }
   ],
   "source": [
    "test_data_dict = test_data_one_sample['test']\n",
    "test_X = test_data_dict['data']\n",
    "test_X = np.array(test_X)\n",
    "test_y = test_data_dict['visible']\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_data_dict = train_data_one_sample['train']\n",
    "train_y = train_data_dict['visible']\n",
    "prior_1 = np.sum(train_y) / len(train_y)\n",
    "prior_0 = 1 - prior_1\n",
    "priors = [prior_0, prior_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Accuracy is 0.524 for 500 samples\n",
      "    num 1s: 104, num 0s: 397\n"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    single_normal=single_normal_state_intuit_one, \n",
    "    mu_bar=mu_bar_state_intuit_one, \n",
    "    cov=cov_state_intuit_one,\n",
    "    parents=parents_intuit,\n",
    "    priors=priors\n",
    "    )\n",
    "\n",
    "nb = NaiveBayes(single_normal=single_normal_state_intuit_one, priors=priors)\n",
    "nb.test(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BE562",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
